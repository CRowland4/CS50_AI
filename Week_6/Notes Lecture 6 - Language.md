# Week 6 - Language



- **formal grammar**: a system of rules for generating sentences in a language
- ***n*-gram**: a contiguous sequence of `n` items from a piece of text
- **tokenization**: the task of splitting a sequence of characters into pieces (tokens)
- **bag-of-words model**: model that represents text as an unordered collection of words
- **additive smoothing**: adding a value `Î±` to each value in our distribution to smooth the data
- **Laplace smoothing**: adding 1 to each value in our distribution; pretending we've seen each value one more time than we actually have
- **one-hot representation**: representation of meaning as a vector with a single 1, and with other values as 0
- **distributed representation**: representation of meaning distributed across multiple values
- **word2vec model**: model for generating word vectors
